{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**INSTALL DEPENDENCIES**"
      ],
      "metadata": {
        "id": "tl_StzO-NNUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx PyPDF2 pytesseract Pillow openpyxl streamlit together"
      ],
      "metadata": {
        "id": "a1OYiB4XKMRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Analysing model in .csv (Titanic Dataset)**"
      ],
      "metadata": {
        "id": "Uzj_-OuZK1WG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9poBdMoGsPX",
        "outputId": "5e7fae28-4a3d-49a6-bdba-f00c25e3b8cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Analyst Agent: Enter 'exit' to quit, 'view_memory' to see history, or 'clear_memory' to reset.\n",
            "Enter file path (.csv, .xlsx, .txt, .docx, .pdf, .png, .jpg, .jpeg): 1.csv\n",
            "File loaded successfully!\n",
            "Data Analysis: {\n",
            "  \"summary\": {\n",
            "    \"Passengerid\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 655.0,\n",
            "      \"std\": 378.0200611960517,\n",
            "      \"min\": 1.0,\n",
            "      \"25%\": 328.0,\n",
            "      \"50%\": 655.0,\n",
            "      \"75%\": 982.0,\n",
            "      \"max\": 1309.0\n",
            "    },\n",
            "    \"Age\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 29.50318563789152,\n",
            "      \"std\": 12.905240585464622,\n",
            "      \"min\": 0.17,\n",
            "      \"25%\": 22.0,\n",
            "      \"50%\": 28.0,\n",
            "      \"75%\": 35.0,\n",
            "      \"max\": 80.0\n",
            "    },\n",
            "    \"Fare\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 33.28108563789152,\n",
            "      \"std\": 51.74149976752607,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 7.8958,\n",
            "      \"50%\": 14.4542,\n",
            "      \"75%\": 31.275,\n",
            "      \"max\": 512.3292\n",
            "    },\n",
            "    \"Sex\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.3559969442322384,\n",
            "      \"std\": 0.47899728344132936,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 1.0,\n",
            "      \"max\": 1.0\n",
            "    },\n",
            "    \"sibsp\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.4988540870893812,\n",
            "      \"std\": 1.0416583905960977,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 1.0,\n",
            "      \"max\": 8.0\n",
            "    },\n",
            "    \"zero\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.1\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.2\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.3\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.4\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.5\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.6\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"Parch\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.3850267379679144,\n",
            "      \"std\": 0.8655602753495125,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 9.0\n",
            "    },\n",
            "    \"zero.7\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.8\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.9\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.10\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.11\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.12\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.13\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.14\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"Pclass\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 2.294881588999236,\n",
            "      \"std\": 0.8378360189701319,\n",
            "      \"min\": 1.0,\n",
            "      \"25%\": 2.0,\n",
            "      \"50%\": 3.0,\n",
            "      \"75%\": 3.0,\n",
            "      \"max\": 3.0\n",
            "    },\n",
            "    \"zero.15\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.16\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"Embarked\": {\n",
            "      \"count\": 1307.0,\n",
            "      \"mean\": 1.4927314460596786,\n",
            "      \"std\": 0.8146255675254218,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 1.0,\n",
            "      \"50%\": 2.0,\n",
            "      \"75%\": 2.0,\n",
            "      \"max\": 2.0\n",
            "    },\n",
            "    \"zero.17\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"zero.18\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.0,\n",
            "      \"std\": 0.0,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 0.0,\n",
            "      \"max\": 0.0\n",
            "    },\n",
            "    \"2urvived\": {\n",
            "      \"count\": 1309.0,\n",
            "      \"mean\": 0.2612681436210848,\n",
            "      \"std\": 0.4394936401080235,\n",
            "      \"min\": 0.0,\n",
            "      \"25%\": 0.0,\n",
            "      \"50%\": 0.0,\n",
            "      \"75%\": 1.0,\n",
            "      \"max\": 1.0\n",
            "    }\n",
            "  },\n",
            "  \"missing_values\": {\n",
            "    \"Passengerid\": 0,\n",
            "    \"Age\": 0,\n",
            "    \"Fare\": 0,\n",
            "    \"Sex\": 0,\n",
            "    \"sibsp\": 0,\n",
            "    \"zero\": 0,\n",
            "    \"zero.1\": 0,\n",
            "    \"zero.2\": 0,\n",
            "    \"zero.3\": 0,\n",
            "    \"zero.4\": 0,\n",
            "    \"zero.5\": 0,\n",
            "    \"zero.6\": 0,\n",
            "    \"Parch\": 0,\n",
            "    \"zero.7\": 0,\n",
            "    \"zero.8\": 0,\n",
            "    \"zero.9\": 0,\n",
            "    \"zero.10\": 0,\n",
            "    \"zero.11\": 0,\n",
            "    \"zero.12\": 0,\n",
            "    \"zero.13\": 0,\n",
            "    \"zero.14\": 0,\n",
            "    \"Pclass\": 0,\n",
            "    \"zero.15\": 0,\n",
            "    \"zero.16\": 0,\n",
            "    \"Embarked\": 2,\n",
            "    \"zero.17\": 0,\n",
            "    \"zero.18\": 0,\n",
            "    \"2urvived\": 0\n",
            "  },\n",
            "  \"dtypes\": {\n",
            "    \"Passengerid\": \"int64\",\n",
            "    \"Age\": \"float64\",\n",
            "    \"Fare\": \"float64\",\n",
            "    \"Sex\": \"int64\",\n",
            "    \"sibsp\": \"int64\",\n",
            "    \"zero\": \"int64\",\n",
            "    \"zero.1\": \"int64\",\n",
            "    \"zero.2\": \"int64\",\n",
            "    \"zero.3\": \"int64\",\n",
            "    \"zero.4\": \"int64\",\n",
            "    \"zero.5\": \"int64\",\n",
            "    \"zero.6\": \"int64\",\n",
            "    \"Parch\": \"int64\",\n",
            "    \"zero.7\": \"int64\",\n",
            "    \"zero.8\": \"int64\",\n",
            "    \"zero.9\": \"int64\",\n",
            "    \"zero.10\": \"int64\",\n",
            "    \"zero.11\": \"int64\",\n",
            "    \"zero.12\": \"int64\",\n",
            "    \"zero.13\": \"int64\",\n",
            "    \"zero.14\": \"int64\",\n",
            "    \"Pclass\": \"int64\",\n",
            "    \"zero.15\": \"int64\",\n",
            "    \"zero.16\": \"int64\",\n",
            "    \"Embarked\": \"float64\",\n",
            "    \"zero.17\": \"int64\",\n",
            "    \"zero.18\": \"int64\",\n",
            "    \"2urvived\": \"int64\"\n",
            "  }\n",
            "}\n",
            "Enter plot type (histogram, bar, scatter): histogram\n",
            "Enter column name (available: ['Passengerid', 'Age', 'Fare', 'Sex', 'sibsp', 'zero', 'zero.1', 'zero.2', 'zero.3', 'zero.4', 'zero.5', 'zero.6', 'Parch', 'zero.7', 'zero.8', 'zero.9', 'zero.10', 'zero.11', 'zero.12', 'zero.13', 'zero.14', 'Pclass', 'zero.15', 'zero.16', 'Embarked', 'zero.17', 'zero.18', '2urvived']): 2urvived\n",
            "Visualization saved as visualization_0.png\n",
            "Description: The histogram plot generated for the column \"2urvived\" provides a visual representation of the distribution of the values in this column. As a data analyst, upon examining the plot, I notice that the distribution is binary, with the majority of the values concentrated at 0 and a smaller proportion at 1.\n",
            "\n",
            "The histogram reveals that approximately 74% of the passengers did not survive (value = 0), while around 26% survived (value = 1). This is evident from the height of the bars, where the bar at 0 is significantly taller than the bar at 1.\n",
            "\n",
            "The binary nature of the distribution is expected, as the column \"2urvived\" likely represents a binary outcome (survived or not survived). The plot effectively communicates the proportion of passengers who survived versus those who did not, providing a quick and intuitive understanding of the survival rate in the dataset.\n",
            "\n",
            "Overall, the histogram plot for \"2urvived\" offers a clear and concise visualization\n",
            "Visualization opened in default viewer.\n",
            "Ask a question about the data (or 'next' for new file, 'exit' to quit, 'view_memory' to see history, 'clear_memory' to reset): what is dataset about\n",
            "Answer: Based on the provided data summary and memory of past interactions, the dataset appears to be related to the Titanic passenger data. Here's a breakdown of the insights:\n",
            "\n",
            "1. **Dataset Overview**: The dataset contains 1309 rows and multiple columns, including `Passengerid`, `Age`, `Fare`, `Sex`, `sibsp`, `Parch`, `Pclass`, `Embarked`, and `2urvived`.\n",
            "\n",
            "2. **Column Insights**:\n",
            "   - `Passengerid`: A unique identifier for each passenger, ranging from 1 to 1309.\n",
            "   - `Age`: The age of passengers, ranging from 0.17 to 80 years, with a mean age of approximately 29.5 years.\n",
            "   - `Fare`: The fare paid by passengers, ranging from 0 to 512.3292, with a mean fare of approximately 33.28.\n",
            "   - `Sex`: The gender of passengers, encoded as 0 or 1, with a mean of 0.356, indicating that about 35.6% of the passengers are likely female (assuming 1 represents female).\n",
            "   - `sibsp` and `Parch`: These columns likely represent the number of siblings/spouses and parents/children aboard, respectively. Most passengers have a value of 0 for both, indicating they are traveling alone.\n",
            "   - `Pclass`: The socio-economic status of passengers, with 1 being the highest and 3 being the lowest. The mean is around 2.29, indicating that most passengers are from the lower socio-economic classes.\n",
            "   - `Embarked`: The port of embarkation, encoded as 0, 1, or 2, with a mean of 1.49, suggesting that most passengers embarked from either port 1 or 2.\n",
            "   - `2urvived`: Likely a typo or encoding for `Survived`, indicating whether a passenger survived (1) or not (0). The mean survival rate is approximately 26.1%.\n",
            "\n",
            "3. **Missing Values**: The dataset has missing values only in the `Embarked` column, with 2 missing values.\n",
            "\n",
            "4. **Data Types**: The data types are mostly appropriate for the columns, with `int64` for categorical and count data, and `float64` for continuous data like `Age` and `Fare`.\n",
            "\n",
            "Given the column names and the data summary, it is likely that\n",
            "Ask a question about the data (or 'next' for new file, 'exit' to quit, 'view_memory' to see history, 'clear_memory' to reset): How did age affect survival chances for passengers?\n",
            "Answer: To analyze how age affected survival chances for passengers, we need to examine the relationship between the `Age` and `2urvived` columns in the dataset.\n",
            "\n",
            "### Step 1: Understanding the Data\n",
            "\n",
            "From the provided summary:\n",
            "- `Age` ranges from 0.17 to 80 years with a mean of 29.503 years.\n",
            "- `2urvived` (likely `Survived`) is a binary column where 0 indicates did not survive and 1 indicates survived. The mean survival rate is 26.1%.\n",
            "\n",
            "### Step 2: Analyzing the Relationship Between Age and Survival\n",
            "\n",
            "To understand how age affected survival chances, we can:\n",
            "1. **Compare the age distribution** of survivors and non-survivors.\n",
            "2. **Calculate survival rates** across different age groups.\n",
            "\n",
            "#### 2.1 Comparing Age Distribution\n",
            "\n",
            "Let's hypothetically compare the age distribution for survivors and non-survivors:\n",
            "- For survivors (`2urvived` = 1), we would expect a certain age distribution.\n",
            "- For non-survivors (`2urvived` = 0), we would expect another age distribution.\n",
            "\n",
            "If the mean age or the distribution of ages significantly differs between survivors and non-survivors, it could indicate that age played a role in survival chances.\n",
            "\n",
            "#### 2.2 Calculating Survival Rates Across Age Groups\n",
            "\n",
            "We can categorize `Age` into groups (e.g., children < 18, adults 18-60, elderly > 60) and calculate the survival rate for each group.\n",
            "\n",
            "### Insights Based on Hypothetical Analysis\n",
            "\n",
            "Assuming we performed the analysis:\n",
            "- **Children** might have had a higher survival rate compared to adults or the elderly, as they were often given priority during rescue operations.\n",
            "- **Elderly** passengers might have had lower survival rates due to potential health issues or other factors.\n",
            "\n",
            "### Example Analysis\n",
            "\n",
            "Let's say, after analyzing the data:\n",
            "- The mean age of survivors is slightly lower than that of non-survivors.\n",
            "- Children under 18 have a survival rate of 40%, significantly higher than the overall survival rate of 26.1%.\n",
            "- Elderly passengers (> 60 years) have a lower survival rate, around 15%.\n",
            "\n",
            "### Conclusion\n",
            "\n",
            "Based on the hypothetical analysis, age appears to have affected survival chances. Children had a higher survival rate, potentially due to priority during rescue operations. In contrast, elderly passengers faced lower survival rates, possibly due to health issues\n",
            "Ask a question about the data (or 'next' for new file, 'exit' to quit, 'view_memory' to see history, 'clear_memory' to reset): what was me previous question\n",
            "Answer: Your previous question was: \"How did age affect survival chances for passengers?\" \n",
            "\n",
            "To directly answer your current question, \"what was my previous question,\" I relied on the memory of past interactions, which stored the sequence of our conversation. This allowed me to recall that your preceding inquiry was about analyzing the impact of age on survival rates among passengers in the dataset.\n",
            "Ask a question about the data (or 'next' for new file, 'exit' to quit, 'view_memory' to see history, 'clear_memory' to reset): exit\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import docx\n",
        "import PyPDF2\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from together import Together\n",
        "import io\n",
        "import json\n",
        "from datetime import datetime\n",
        "import subprocess\n",
        "import platform\n",
        "\n",
        "os.environ['TOGETHER_API_KEY'] = 'tgp_v1_ZWeUvKN-bQqNQDHRmw_0nfLGarqsPRC0eDXlOY75pnA'\n",
        "client = Together(api_key=os.environ['TOGETHER_API_KEY'])\n",
        "MODEL_NAME = 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8'\n",
        "\n",
        "MEMORY_FILE = 'memory.json'\n",
        "\n",
        "def load_memory():\n",
        "    if os.path.exists(MEMORY_FILE):\n",
        "        with open(MEMORY_FILE, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    return {'files': [], 'interactions': []}\n",
        "\n",
        "def save_memory(memory):\n",
        "    with open(MEMORY_FILE, 'w', encoding='utf-8') as f:\n",
        "        json.dump(memory, f, indent=2)\n",
        "\n",
        "def clear_memory():\n",
        "    memory = {'files': [], 'interactions': []}\n",
        "    save_memory(memory)\n",
        "    return \"Memory cleared.\"\n",
        "\n",
        "def read_text_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "def read_doc_file(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    return ' '.join([para.text for para in doc.paragraphs])\n",
        "\n",
        "def read_pdf_file(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = ''\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + ' '\n",
        "        return text\n",
        "\n",
        "def read_image_file(file_path):\n",
        "    image = Image.open(file_path)\n",
        "    text = pytesseract.image_to_string(image)\n",
        "    return text\n",
        "\n",
        "def read_excel_csv_file(file_path):\n",
        "    if file_path.endswith('.csv'):\n",
        "        encodings = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']\n",
        "        for encoding in encodings:\n",
        "            try:\n",
        "                return pd.read_csv(file_path, encoding=encoding)\n",
        "            except UnicodeDecodeError:\n",
        "                continue\n",
        "        raise ValueError(f\"Unable to decode CSV file {file_path} with tried encodings: {encodings}\")\n",
        "    elif file_path.endswith('.xlsx'):\n",
        "        return pd.read_excel(file_path)\n",
        "    return None\n",
        "\n",
        "def process_file(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File {file_path} does not exist\")\n",
        "    if file_path.endswith(('.txt', '.doc', '.docx')):\n",
        "        return read_doc_file(file_path) if file_path.endswith(('.doc', '.docx')) else read_text_file(file_path)\n",
        "    elif file_path.endswith('.pdf'):\n",
        "        return read_pdf_file(file_path)\n",
        "    elif file_path.endswith(('.png', '.jpg', '.jpeg')):\n",
        "        return read_image_file(file_path)\n",
        "    elif file_path.endswith(('.csv', '.xlsx')):\n",
        "        return read_excel_csv_file(file_path)\n",
        "    else:\n",
        "        raise ValueError('Unsupported file type')\n",
        "\n",
        "def open_visualization(file_path):\n",
        "    try:\n",
        "        if platform.system() == 'Windows':\n",
        "            os.startfile(file_path)\n",
        "        elif platform.system() == 'Darwin':\n",
        "            subprocess.run(['open', file_path])\n",
        "        else:\n",
        "            subprocess.run(['xdg-open', file_path])\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to open visualization: {e}\")\n",
        "        return False\n",
        "\n",
        "class DataAnalystAgent:\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "        self.text_data = None\n",
        "        self.client = client\n",
        "        self.memory = load_memory()\n",
        "\n",
        "    def load_data(self, file_path):\n",
        "        data = process_file(file_path)\n",
        "        if isinstance(data, pd.DataFrame):\n",
        "            self.data = data\n",
        "        else:\n",
        "            self.text_data = data\n",
        "\n",
        "        self.memory['files'].append({\n",
        "            'file_path': file_path,\n",
        "            'type': 'structured' if isinstance(data, pd.DataFrame) else 'text',\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        save_memory(self.memory)\n",
        "\n",
        "    def analyze_data(self):\n",
        "        if self.data is not None:\n",
        "            dtypes_dict = {col: str(dtype) for col, dtype in self.data.dtypes.items()}\n",
        "            analysis = {\n",
        "                'summary': self.data.describe().to_dict(),\n",
        "                'missing_values': self.data.isnull().sum().to_dict(),\n",
        "                'dtypes': dtypes_dict\n",
        "            }\n",
        "\n",
        "            self.memory['files'][-1]['analysis'] = analysis\n",
        "            save_memory(self.memory)\n",
        "            return analysis\n",
        "        return {'message': 'No structured data available for analysis'}\n",
        "\n",
        "    def generate_visualization(self, plot_type='histogram', column=None):\n",
        "        if self.data is None:\n",
        "            return 'No data available for visualization'\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        if plot_type == 'histogram' and column:\n",
        "            sns.histplot(self.data[column], kde=True)\n",
        "            plt.title(f'Histogram of {column}')\n",
        "        elif plot_type == 'bar' and column:\n",
        "            self.data[column].value_counts().plot(kind='bar')\n",
        "            plt.title(f'Bar Plot of {column}')\n",
        "        elif plot_type == 'scatter' and column:\n",
        "            if len(self.data.columns) >= 2:\n",
        "                sns.scatterplot(x=self.data.columns[0], y=self.data.columns[1], data=self.data)\n",
        "                plt.title(f'Scatter Plot of {self.data.columns[0]} vs {self.data.columns[1]}')\n",
        "        else:\n",
        "            return 'Invalid plot type or column'\n",
        "\n",
        "        output_file = f'visualization_{len(self.memory[\"interactions\"])}.png'\n",
        "        plt.savefig(output_file)\n",
        "        plt.close()\n",
        "\n",
        "        self.memory['interactions'].append({\n",
        "            'type': 'visualization',\n",
        "            'plot_type': plot_type,\n",
        "            'column': column,\n",
        "            'file': output_file,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        save_memory(self.memory)\n",
        "\n",
        "        description = self.describe_visualization(plot_type, column, output_file)\n",
        "\n",
        "        opened = open_visualization(output_file)\n",
        "        return f'Visualization saved as {output_file}\\nDescription: {description}\\n' + \\\n",
        "               (f'Visualization opened in default viewer.' if opened else 'Please open the visualization manually.')\n",
        "\n",
        "    def describe_visualization(self, plot_type, column, output_file):\n",
        "        context = ''\n",
        "        if self.data is not None:\n",
        "            context += f'Data summary: {json.dumps(self.analyze_data(), indent=2)}\\n'\n",
        "        context += f'Generated a {plot_type} plot for column {column} saved as {output_file}.'\n",
        "\n",
        "        prompt = f'Context: {context}\\nDescribe the visualization as a data analyst, focusing on key features and insights.'\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[\n",
        "                {'role': 'system', 'content': 'You are a data analyst. Describe the visualization based on the given context.'},\n",
        "                {'role': 'user', 'content': prompt}\n",
        "            ],\n",
        "            max_tokens=200\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    def answer_question(self, question):\n",
        "        context = ''\n",
        "\n",
        "        if self.data is not None:\n",
        "            context += f'Current Data summary: {json.dumps(self.analyze_data(), indent=2)}\\n'\n",
        "        if self.text_data:\n",
        "            context += f'Current Text data: {self.text_data[:1000]}...\\n'\n",
        "\n",
        "        context += 'Memory of past interactions:\\n'\n",
        "        for file_info in self.memory['files']:\n",
        "            context += f\"File: {file_info['file_path']} (Type: {file_info['type']}, Loaded: {file_info['timestamp']})\\n\"\n",
        "            if 'analysis' in file_info:\n",
        "                context += f\"Analysis: {json.dumps(file_info['analysis'], indent=2)}\\n\"\n",
        "        for interaction in self.memory['interactions']:\n",
        "            if interaction['type'] == 'visualization':\n",
        "                context += f\"Visualization: {interaction['plot_type']} on {interaction['column']} saved as {interaction['file']} at {interaction['timestamp']}\\n\"\n",
        "            elif interaction['type'] == 'question':\n",
        "                context += f\"Question: {interaction['question']} | Answer: {interaction['answer']} at {interaction['timestamp']}\\n\"\n",
        "\n",
        "        prompt = f'Context: {context}\\nQuestion: {question}\\nAnswer as a data analyst, providing insights based on the available data, text, and memory of past interactions.'\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[\n",
        "                {'role': 'system', 'content': 'You are a data analyst. Provide accurate and insightful answers based on the given data, text, and memory.'},\n",
        "                {'role': 'user', 'content': prompt}\n",
        "            ],\n",
        "            max_tokens=500\n",
        "        )\n",
        "        answer = response.choices[0].message.content\n",
        "\n",
        "        self.memory['interactions'].append({\n",
        "            'type': 'question',\n",
        "            'question': question,\n",
        "            'answer': answer,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        save_memory(self.memory)\n",
        "        return answer\n",
        "\n",
        "    def view_memory(self):\n",
        "        return json.dumps(self.memory, indent=2)\n",
        "\n",
        "def main():\n",
        "    agent = DataAnalystAgent()\n",
        "    print(\"Data Analyst Agent: Enter 'exit' to quit, 'view_memory' to see history, or 'clear_memory' to reset.\")\n",
        "\n",
        "    while True:\n",
        "        file_path = input(\"Enter file path (.csv, .xlsx, .txt, .docx, .pdf, .png, .jpg, .jpeg): \").strip().strip('\"')\n",
        "        if file_path.lower() == 'exit':\n",
        "            break\n",
        "        if file_path.lower() == 'view_memory':\n",
        "            print(\"Memory Contents:\", agent.view_memory())\n",
        "            continue\n",
        "        if file_path.lower() == 'clear_memory':\n",
        "            print(clear_memory())\n",
        "            agent.memory = load_memory()\n",
        "            continue\n",
        "        try:\n",
        "            agent.load_data(file_path)\n",
        "            print(\"File loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading file: {e}\")\n",
        "            continue\n",
        "\n",
        "        if agent.data is not None:\n",
        "            print(\"Data Analysis:\", json.dumps(agent.analyze_data(), indent=2))\n",
        "            plot_type = input(\"Enter plot type (histogram, bar, scatter): \").strip().lower()\n",
        "            if plot_type in ['histogram', 'bar']:\n",
        "                column = input(f\"Enter column name (available: {list(agent.data.columns)}): \").strip()\n",
        "                if column in agent.data.columns:\n",
        "                    result = agent.generate_visualization(plot_type, column)\n",
        "                    print(result)\n",
        "                else:\n",
        "                    print(\"Invalid column name.\")\n",
        "            elif plot_type == 'scatter':\n",
        "                result = agent.generate_visualization(plot_type)\n",
        "                print(result)\n",
        "            else:\n",
        "                print(\"Invalid plot type.\")\n",
        "\n",
        "        while True:\n",
        "            question = input(\"Ask a question about the data (or 'next' for new file, 'exit' to quit, 'view_memory' to see history, 'clear_memory' to reset): \").strip()\n",
        "            if question.lower() == 'exit':\n",
        "                return\n",
        "            if question.lower() == 'next':\n",
        "                break\n",
        "            if question.lower() == 'view_memory':\n",
        "                print(\"Memory Contents:\", agent.view_memory())\n",
        "                continue\n",
        "            if question.lower() == 'clear_memory':\n",
        "                print(clear_memory())\n",
        "                agent.memory = load_memory()\n",
        "                continue\n",
        "            try:\n",
        "                answer = agent.answer_question(question)\n",
        "                print(\"Answer:\", answer)\n",
        "            except Exception as e:\n",
        "                print(f\"Error answering question: {e}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Analysing PDF (YT chatbot)**"
      ],
      "metadata": {
        "id": "Bw7NoyuIK6gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import docx\n",
        "import PyPDF2\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from together import Together\n",
        "import io\n",
        "import json\n",
        "from datetime import datetime\n",
        "import subprocess\n",
        "import platform\n",
        "\n",
        "os.environ['TOGETHER_API_KEY'] = 'tgp_v1_5Yf5j-Vu39EjPkLKg3InorzjMbHzeOtgT_KmqAXajzk'\n",
        "client = Together(api_key=os.environ['TOGETHER_API_KEY'])\n",
        "MODEL_NAME = 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8'\n",
        "\n",
        "MEMORY_FILE = 'memory.json'\n",
        "\n",
        "def load_memory():\n",
        "    if os.path.exists(MEMORY_FILE):\n",
        "        with open(MEMORY_FILE, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    return {'files': [], 'interactions': []}\n",
        "\n",
        "def save_memory(memory):\n",
        "    with open(MEMORY_FILE, 'w', encoding='utf-8') as f:\n",
        "        json.dump(memory, f, indent=2)\n",
        "\n",
        "def clear_memory():\n",
        "    memory = {'files': [], 'interactions': []}\n",
        "    save_memory(memory)\n",
        "    return \"Memory cleared.\"\n",
        "\n",
        "def read_text_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "def read_doc_file(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    return ' '.join([para.text for para in doc.paragraphs])\n",
        "\n",
        "def read_pdf_file(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = ''\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + ' '\n",
        "        return text\n",
        "\n",
        "def read_image_file(file_path):\n",
        "    image = Image.open(file_path)\n",
        "    text = pytesseract.image_to_string(image)\n",
        "    return text\n",
        "\n",
        "def read_excel_csv_file(file_path):\n",
        "    if file_path.endswith('.csv'):\n",
        "        encodings = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']\n",
        "        for encoding in encodings:\n",
        "            try:\n",
        "                return pd.read_csv(file_path, encoding=encoding)\n",
        "            except UnicodeDecodeError:\n",
        "                continue\n",
        "        raise ValueError(f\"Unable to decode CSV file {file_path} with tried encodings: {encodings}\")\n",
        "    elif file_path.endswith('.xlsx'):\n",
        "        return pd.read_excel(file_path)\n",
        "    return None\n",
        "\n",
        "def process_file(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File {file_path} does not exist\")\n",
        "    if file_path.endswith(('.txt', '.doc', '.docx')):\n",
        "        return read_doc_file(file_path) if file_path.endswith(('.doc', '.docx')) else read_text_file(file_path)\n",
        "    elif file_path.endswith('.pdf'):\n",
        "        return read_pdf_file(file_path)\n",
        "    elif file_path.endswith(('.png', '.jpg', '.jpeg')):\n",
        "        return read_image_file(file_path)\n",
        "    elif file_path.endswith(('.csv', '.xlsx')):\n",
        "        return read_excel_csv_file(file_path)\n",
        "    else:\n",
        "        raise ValueError('Unsupported file type')\n",
        "\n",
        "def open_visualization(file_path):\n",
        "    try:\n",
        "        if platform.system() == 'Windows':\n",
        "            os.startfile(file_path)\n",
        "        elif platform.system() == 'Darwin':\n",
        "            subprocess.run(['open', file_path])\n",
        "        else:\n",
        "            subprocess.run(['xdg-open', file_path])\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to open visualization: {e}\")\n",
        "        return False\n",
        "\n",
        "class DataAnalystAgent:\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "        self.text_data = None\n",
        "        self.client = client\n",
        "        self.memory = load_memory()\n",
        "\n",
        "    def load_data(self, file_path):\n",
        "        data = process_file(file_path)\n",
        "        if isinstance(data, pd.DataFrame):\n",
        "            self.data = data\n",
        "        else:\n",
        "            self.text_data = data\n",
        "        self.memory['files'].append({\n",
        "            'file_path': file_path,\n",
        "            'type': 'structured' if isinstance(data, pd.DataFrame) else 'text',\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        save_memory(self.memory)\n",
        "\n",
        "    def analyze_data(self):\n",
        "        if self.data is not None:\n",
        "            dtypes_dict = {col: str(dtype) for col, dtype in self.data.dtypes.items()}\n",
        "            analysis = {\n",
        "                'summary': self.data.describe().to_dict(),\n",
        "                'missing_values': self.data.isnull().sum().to_dict(),\n",
        "                'dtypes': dtypes_dict\n",
        "            }\n",
        "            self.memory['files'][-1]['analysis'] = analysis\n",
        "            save_memory(self.memory)\n",
        "            return analysis\n",
        "        return {'message': 'No structured data available for analysis'}\n",
        "\n",
        "    def generate_visualization(self, plot_type='histogram', column=None):\n",
        "        if self.data is None:\n",
        "            return 'No data available for visualization'\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        if plot_type == 'histogram' and column:\n",
        "            sns.histplot(self.data[column], kde=True)\n",
        "            plt.title(f'Histogram of {column}')\n",
        "        elif plot_type == 'bar' and column:\n",
        "            self.data[column].value_counts().plot(kind='bar')\n",
        "            plt.title(f'Bar Plot of {column}')\n",
        "        elif plot_type == 'scatter' and column:\n",
        "            if len(self.data.columns) >= 2:\n",
        "                sns.scatterplot(x=self.data.columns[0], y=self.data.columns[1], data=self.data)\n",
        "                plt.title(f'Scatter Plot of {self.data.columns[0]} vs {self.data.columns[1]}')\n",
        "        else:\n",
        "            return 'Invalid plot type or column'\n",
        "\n",
        "        output_file = f'visualization_{len(self.memory[\"interactions\"])}.png'\n",
        "        plt.savefig(output_file)\n",
        "        plt.close()\n",
        "\n",
        "        self.memory['interactions'].append({\n",
        "            'type': 'visualization',\n",
        "            'plot_type': plot_type,\n",
        "            'column': column,\n",
        "            'file': output_file,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        save_memory(self.memory)\n",
        "\n",
        "        description = self.describe_visualization(plot_type, column, output_file)\n",
        "        opened = open_visualization(output_file)\n",
        "        return f'Visualization saved as {output_file}\\nDescription: {description}\\n' + \\\n",
        "               (f'Visualization opened in default viewer.' if opened else 'Please open the visualization manually.')\n",
        "\n",
        "    def describe_visualization(self, plot_type, column, output_file):\n",
        "        context = ''\n",
        "        if self.data is not None:\n",
        "            context += f'Data summary: {json.dumps(self.analyze_data(), indent=2)}\\n'\n",
        "        context += f'Generated a {plot_type} plot for column {column} saved as {output_file}.'\n",
        "\n",
        "        prompt = f'Context: {context}\\nDescribe the visualization as a data analyst, focusing on key features and insights.'\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[\n",
        "                {'role': 'system', 'content': 'You are a data analyst. Describe the visualization based on the given context.'},\n",
        "                {'role': 'user', 'content': prompt}\n",
        "            ],\n",
        "            max_tokens=200\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    def answer_question(self, question):\n",
        "        context = ''\n",
        "\n",
        "        if self.data is not None:\n",
        "            context += f'Current Data summary: {json.dumps(self.analyze_data(), indent=2)}\\n'\n",
        "        if self.text_data:\n",
        "            context += f'Current Text data: {self.text_data[:1000]}...\\n'\n",
        "        context += 'Memory of past interactions:\\n'\n",
        "        for file_info in self.memory['files']:\n",
        "            context += f\"File: {file_info['file_path']} (Type: {file_info['type']}, Loaded: {file_info['timestamp']})\\n\"\n",
        "            if 'analysis' in file_info:\n",
        "                context += f\"Analysis: {json.dumps(file_info['analysis'], indent=2)}\\n\"\n",
        "        for interaction in self.memory['interactions']:\n",
        "            if interaction['type'] == 'visualization':\n",
        "                context += f\"Visualization: {interaction['plot_type']} on {interaction['column']} saved as {interaction['file']} at {interaction['timestamp']}\\n\"\n",
        "            elif interaction['type'] == 'question':\n",
        "                context += f\"Question: {interaction['question']} | Answer: {interaction['answer']} at {interaction['timestamp']}\\n\"\n",
        "\n",
        "        prompt = f'Context: {context}\\nQuestion: {question}\\nAnswer as a data analyst, providing insights based on the available data, text, and memory of past interactions.'\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[\n",
        "                {'role': 'system', 'content': 'You are a data analyst. Provide accurate and insightful answers based on the given data, text, and memory.'},\n",
        "                {'role': 'user', 'content': prompt}\n",
        "            ],\n",
        "            max_tokens=500\n",
        "        )\n",
        "        answer = response.choices[0].message.content\n",
        "        self.memory['interactions'].append({\n",
        "            'type': 'question',\n",
        "            'question': question,\n",
        "            'answer': answer,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        save_memory(self.memory)\n",
        "        return answer\n",
        "\n",
        "    def view_memory(self):\n",
        "        return json.dumps(self.memory, indent=2)\n",
        "\n",
        "def main():\n",
        "    agent = DataAnalystAgent()\n",
        "    print(\"Data Analyst Agent: Enter 'exit' to quit, 'view_memory' to see history, or 'clear_memory' to reset.\")\n",
        "\n",
        "    while True:\n",
        "        file_path = input(\"Enter file path (.csv, .xlsx, .txt, .docx, .pdf, .png, .jpg, .jpeg): \").strip().strip('\"')\n",
        "        if file_path.lower() == 'exit':\n",
        "            break\n",
        "        if file_path.lower() == 'view_memory':\n",
        "            print(\"Memory Contents:\", agent.view_memory())\n",
        "            continue\n",
        "        if file_path.lower() == 'clear_memory':\n",
        "            print(clear_memory())\n",
        "            agent.memory = load_memory()\n",
        "            continue\n",
        "        try:\n",
        "            agent.load_data(file_path)\n",
        "            print(\"File loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading file: {e}\")\n",
        "            continue\n",
        "\n",
        "        if agent.data is not None:\n",
        "            print(\"Data Analysis:\", json.dumps(agent.analyze_data(), indent=2))\n",
        "            plot_type = input(\"Enter plot type (histogram, bar, scatter): \").strip().lower()\n",
        "            if plot_type in ['histogram', 'bar']:\n",
        "                column = input(f\"Enter column name (available: {list(agent.data.columns)}): \").strip()\n",
        "                if column in agent.data.columns:\n",
        "                    result = agent.generate_visualization(plot_type, column)\n",
        "                    print(result)\n",
        "                else:\n",
        "                    print(\"Invalid column name.\")\n",
        "            elif plot_type == 'scatter':\n",
        "                result = agent.generate_visualization(plot_type)\n",
        "                print(result)\n",
        "            else:\n",
        "                print(\"Invalid plot type.\")\n",
        "\n",
        "        while True:\n",
        "            question = input(\"Ask a question about the data (or 'next' for new file, 'exit' to quit, 'view_memory' to see history, 'clear_memory' to reset): \").strip()\n",
        "            if question.lower() == 'exit':\n",
        "                return\n",
        "            if question.lower() == 'next':\n",
        "                break\n",
        "            if question.lower() == 'view_memory':\n",
        "                print(\"Memory Contents:\", agent.view_memory())\n",
        "                continue\n",
        "            if question.lower() == 'clear_memory':\n",
        "                print(clear_memory())\n",
        "                agent.memory = load_memory()\n",
        "                continue\n",
        "            try:\n",
        "                answer = agent.answer_question(question)\n",
        "                print(\"Answer:\", answer)\n",
        "            except Exception as e:\n",
        "                print(f\"Error answering question: {e}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI2qLYQ0K9a9",
        "outputId": "58c05a68-a3f6-43ba-ca89-e408d26d4518"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Analyst Agent: Enter 'exit' to quit, 'view_memory' to see history, or 'clear_memory' to reset.\n",
            "Enter file path (.csv, .xlsx, .txt, .docx, .pdf, .png, .jpg, .jpeg): YTchatbot_report.pdf\n",
            "File loaded successfully!\n",
            "Ask a question about the data (or 'next' for new file, 'exit' to quit, 'view_memory' to see history, 'clear_memory' to reset): clear_memory\n",
            "Memory cleared.\n",
            "Ask a question about the data (or 'next' for new file, 'exit' to quit, 'view_memory' to see history, 'clear_memory' to reset): wha ts this pdf about\n",
            "Answer: Based on the provided text data, I will analyze it and provide an insightful answer.\n",
            "\n",
            "The text appears to be a personal profile or a resume of an individual, Manshu555, highlighting their programming experience and a significant project they worked on. \n",
            "\n",
            "As a data analyst, my analysis of the text reveals the following key points:\n",
            "\n",
            "1. **Primary Programming Experience**: The author has extensive experience in Python-based backend development, with a focus on integrating machine learning models and API services.\n",
            "2. **Technical Stack**: The primary technical stack includes FastAPI for building high-performance APIs and HuggingFace transformers for natural language processing (NLP).\n",
            "3. **Project Overview**: The biggest project worked on is a YouTube Chatbot designed for real-time Q&A over video transcripts, combining NLP capabilities with API infrastructure.\n",
            "4. **Independent Contributions**: The author independently built the complete backend system for the chatbot, including transcript processing and chunking logic.\n",
            "\n",
            "Given the content and structure of the text, it is likely that this document is a personal portfolio or a resume, aiming to showcase the author's technical skills and experience in programming and project development.\n",
            "\n",
            "Therefore, as a data analyst, my answer to the question \"what's this PDF about?\" would be that this document is a personal profile or resume highlighting the author's programming experience, technical skills, and a significant project they worked on, specifically a YouTube Chatbot using NLP and API infrastructure.\n",
            "Ask a question about the data (or 'next' for new file, 'exit' to quit, 'view_memory' to see history, 'clear_memory' to reset): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Analysing Image (Black Hole Article in Google Front Page from Wikipedia)**"
      ],
      "metadata": {
        "id": "YZrlxFrpO9JU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import docx\n",
        "import PyPDF2\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from together import Together\n",
        "import io\n",
        "import json\n",
        "from datetime import datetime\n",
        "import subprocess\n",
        "import platform\n",
        "\n",
        "os.environ['TOGETHER_API_KEY'] = 'tgp_v1_5Yf5j-Vu39EjPkLKg3InorzjMbHzeOtgT_KmqAXajzk'\n",
        "client = Together(api_key=os.environ['TOGETHER_API_KEY'])\n",
        "MODEL_NAME = 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8'\n",
        "\n",
        "MEMORY_FILE = 'memory.json'\n",
        "\n",
        "def load_memory():\n",
        "    if os.path.exists(MEMORY_FILE):\n",
        "        with open(MEMORY_FILE, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    return {'files': [], 'interactions': []}\n",
        "\n",
        "def save_memory(memory):\n",
        "    with open(MEMORY_FILE, 'w', encoding='utf-8') as f:\n",
        "        json.dump(memory, f, indent=2)\n",
        "\n",
        "def clear_memory():\n",
        "    memory = {'files': [], 'interactions': []}\n",
        "    save_memory(memory)\n",
        "    return \"Memory cleared.\"\n",
        "\n",
        "def read_text_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "def read_doc_file(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    return ' '.join([para.text for para in doc.paragraphs])\n",
        "\n",
        "def read_pdf_file(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = ''\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + ' '\n",
        "        return text\n",
        "\n",
        "def read_image_file(file_path):\n",
        "    image = Image.open(file_path)\n",
        "    text = pytesseract.image_to_string(image)\n",
        "    return text\n",
        "\n",
        "def read_excel_csv_file(file_path):\n",
        "    if file_path.endswith('.csv'):\n",
        "        encodings = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']\n",
        "        for encoding in encodings:\n",
        "            try:\n",
        "                return pd.read_csv(file_path, encoding=encoding)\n",
        "            except UnicodeDecodeError:\n",
        "                continue\n",
        "        raise ValueError(f\"Unable to decode CSV file {file_path} with tried encodings: {encodings}\")\n",
        "    elif file_path.endswith('.xlsx'):\n",
        "        return pd.read_excel(file_path)\n",
        "    return None\n",
        "\n",
        "def process_file(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File {file_path} does not exist\")\n",
        "    if file_path.endswith(('.txt', '.doc', '.docx')):\n",
        "        return read_doc_file(file_path) if file_path.endswith(('.doc', '.docx')) else read_text_file(file_path)\n",
        "    elif file_path.endswith('.pdf'):\n",
        "        return read_pdf_file(file_path)\n",
        "    elif file_path.endswith(('.png', '.jpg', '.jpeg')):\n",
        "        return read_image_file(file_path)\n",
        "    elif file_path.endswith(('.csv', '.xlsx')):\n",
        "        return read_excel_csv_file(file_path)\n",
        "    else:\n",
        "        raise ValueError('Unsupported file type')\n",
        "\n",
        "def open_visualization(file_path):\n",
        "    try:\n",
        "        if platform.system() == 'Windows':\n",
        "            os.startfile(file_path)\n",
        "        elif platform.system() == 'Darwin':\n",
        "            subprocess.run(['open', file_path])\n",
        "        else:\n",
        "            subprocess.run(['xdg-open', file_path])\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to open visualization: {e}\")\n",
        "        return False\n",
        "\n",
        "class DataAnalystAgent:\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "        self.text_data = None\n",
        "        self.client = client\n",
        "        self.memory = load_memory()\n",
        "\n",
        "    def load_data(self, file_path):\n",
        "        data = process_file(file_path)\n",
        "        if isinstance(data, pd.DataFrame):\n",
        "            self.data = data\n",
        "        else:\n",
        "            self.text_data = data\n",
        "        self.memory['files'].append({\n",
        "            'file_path': file_path,\n",
        "            'type': 'structured' if isinstance(data, pd.DataFrame) else 'text',\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        save_memory(self.memory)\n",
        "\n",
        "    def analyze_data(self):\n",
        "        if self.data is not None:\n",
        "            dtypes_dict = {col: str(dtype) for col, dtype in self.data.dtypes.items()}\n",
        "            analysis = {\n",
        "                'summary': self.data.describe().to_dict(),\n",
        "                'missing_values': self.data.isnull().sum().to_dict(),\n",
        "                'dtypes': dtypes_dict\n",
        "            }\n",
        "            self.memory['files'][-1]['analysis'] = analysis\n",
        "            save_memory(self.memory)\n",
        "            return analysis\n",
        "        return {'message': 'No structured data available for analysis'}\n",
        "\n",
        "    def generate_visualization(self, plot_type='histogram', column=None):\n",
        "        if self.data is None:\n",
        "            return 'No data available for visualization'\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        if plot_type == 'histogram' and column:\n",
        "            sns.histplot(self.data[column], kde=True)\n",
        "            plt.title(f'Histogram of {column}')\n",
        "        elif plot_type == 'bar' and column:\n",
        "            self.data[column].value_counts().plot(kind='bar')\n",
        "            plt.title(f'Bar Plot of {column}')\n",
        "        elif plot_type == 'scatter' and column:\n",
        "            if len(self.data.columns) >= 2:\n",
        "                sns.scatterplot(x=self.data.columns[0], y=self.data.columns[1], data=self.data)\n",
        "                plt.title(f'Scatter Plot of {self.data.columns[0]} vs {self.data.columns[1]}')\n",
        "        else:\n",
        "            return 'Invalid plot type or column'\n",
        "\n",
        "        output_file = f'visualization_{len(self.memory[\"interactions\"])}.png'\n",
        "        plt.savefig(output_file)\n",
        "        plt.close()\n",
        "\n",
        "        self.memory['interactions'].append({\n",
        "            'type': 'visualization',\n",
        "            'plot_type': plot_type,\n",
        "            'column': column,\n",
        "            'file': output_file,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        save_memory(self.memory)\n",
        "\n",
        "        description = self.describe_visualization(plot_type, column, output_file)\n",
        "        opened = open_visualization(output_file)\n",
        "        return f'Visualization saved as {output_file}\\nDescription: {description}\\n' + \\\n",
        "               (f'Visualization opened in default viewer.' if opened else 'Please open the visualization manually.')\n",
        "\n",
        "    def describe_visualization(self, plot_type, column, output_file):\n",
        "        context = ''\n",
        "        if self.data is not None:\n",
        "            context += f'Data summary: {json.dumps(self.analyze_data(), indent=2)}\\n'\n",
        "        context += f'Generated a {plot_type} plot for column {column} saved as {output_file}.'\n",
        "\n",
        "        prompt = f'Context: {context}\\nDescribe the visualization as a data analyst, focusing on key features and insights.'\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[\n",
        "                {'role': 'system', 'content': 'You are a data analyst. Describe the visualization based on the given context.'},\n",
        "                {'role': 'user', 'content': prompt}\n",
        "            ],\n",
        "            max_tokens=200\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    def answer_question(self, question):\n",
        "        context = ''\n",
        "\n",
        "        if self.data is not None:\n",
        "            context += f'Current Data summary: {json.dumps(self.analyze_data(), indent=2)}\\n'\n",
        "        if self.text_data:\n",
        "            context += f'Current Text data: {self.text_data[:1000]}...\\n'\n",
        "        context += 'Memory of past interactions:\\n'\n",
        "        for file_info in self.memory['files']:\n",
        "            context += f\"File: {file_info['file_path']} (Type: {file_info['type']}, Loaded: {file_info['timestamp']})\\n\"\n",
        "            if 'analysis' in file_info:\n",
        "                context += f\"Analysis: {json.dumps(file_info['analysis'], indent=2)}\\n\"\n",
        "        for interaction in self.memory['interactions']:\n",
        "            if interaction['type'] == 'visualization':\n",
        "                context += f\"Visualization: {interaction['plot_type']} on {interaction['column']} saved as {interaction['file']} at {interaction['timestamp']}\\n\"\n",
        "            elif interaction['type'] == 'question':\n",
        "                context += f\"Question: {interaction['question']} | Answer: {interaction['answer']} at {interaction['timestamp']}\\n\"\n",
        "\n",
        "        prompt = f'Context: {context}\\nQuestion: {question}\\nAnswer as a data analyst, providing insights based on the available data, text, and memory of past interactions.'\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[\n",
        "                {'role': 'system', 'content': 'You are a data analyst. Provide accurate and insightful answers based on the given data, text, and memory.'},\n",
        "                {'role': 'user', 'content': prompt}\n",
        "            ],\n",
        "            max_tokens=500\n",
        "        )\n",
        "        answer = response.choices[0].message.content\n",
        "        self.memory['interactions'].append({\n",
        "            'type': 'question',\n",
        "            'question': question,\n",
        "            'answer': answer,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        save_memory(self.memory)\n",
        "        return answer\n",
        "\n",
        "    def view_memory(self):\n",
        "        return json.dumps(self.memory, indent=2)\n",
        "\n",
        "def main():\n",
        "    agent = DataAnalystAgent()\n",
        "    print(\"Data Analyst Agent: Enter 'exit' to quit, 'view_memory' to see history, or 'clear_memory' to reset.\")\n",
        "\n",
        "    while True:\n",
        "        file_path = input(\"Enter file path (.csv, .xlsx, .txt, .docx, .pdf, .png, .jpg, .jpeg): \").strip().strip('\"')\n",
        "        if file_path.lower() == 'exit':\n",
        "            break\n",
        "        if file_path.lower() == 'view_memory':\n",
        "            print(\"Memory Contents:\", agent.view_memory())\n",
        "            continue\n",
        "        if file_path.lower() == 'clear_memory':\n",
        "            print(clear_memory())\n",
        "            agent.memory = load_memory()\n",
        "            continue\n",
        "        try:\n",
        "            agent.load_data(file_path)\n",
        "            print(\"File loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading file: {e}\")\n",
        "            continue\n",
        "\n",
        "        if agent.data is not None:\n",
        "            print(\"Data Analysis:\", json.dumps(agent.analyze_data(), indent=2))\n",
        "            plot_type = input(\"Enter plot type (histogram, bar, scatter): \").strip().lower()\n",
        "            if plot_type in ['histogram', 'bar']:\n",
        "                column = input(f\"Enter column name (available: {list(agent.data.columns)}): \").strip()\n",
        "                if column in agent.data.columns:\n",
        "                    result = agent.generate_visualization(plot_type, column)\n",
        "                    print(result)\n",
        "                else:\n",
        "                    print(\"Invalid column name.\")\n",
        "            elif plot_type == 'scatter':\n",
        "                result = agent.generate_visualization(plot_type)\n",
        "                print(result)\n",
        "            else:\n",
        "                print(\"Invalid plot type.\")\n",
        "\n",
        "        while True:\n",
        "            question = input(\"Ask a question about the data (or 'next' for new file, 'exit' to quit, 'view_memory' to see history, 'clear_memory' to reset): \").strip()\n",
        "            if question.lower() == 'exit':\n",
        "                return\n",
        "            if question.lower() == 'next':\n",
        "                break\n",
        "            if question.lower() == 'view_memory':\n",
        "                print(\"Memory Contents:\", agent.view_memory())\n",
        "                continue\n",
        "            if question.lower() == 'clear_memory':\n",
        "                print(clear_memory())\n",
        "                agent.memory = load_memory()\n",
        "                continue\n",
        "            try:\n",
        "                answer = agent.answer_question(question)\n",
        "                print(\"Answer:\", answer)\n",
        "            except Exception as e:\n",
        "                print(f\"Error answering question: {e}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZLSfaqBLJlR",
        "outputId": "ab1e2a7f-4066-4522-a40c-031e0d5a12ff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Analyst Agent: Enter 'exit' to quit, 'view_memory' to see history, or 'clear_memory' to reset.\n",
            "Enter file path (.csv, .xlsx, .txt, .docx, .pdf, .png, .jpg, .jpeg): 3.png\n",
            "File loaded successfully!\n",
            "Ask a question about the data (or 'next' for new file, 'exit' to quit, 'view_memory' to see history, 'clear_memory' to reset): clear_memory\n",
            "Memory cleared.\n",
            "Ask a question about the data (or 'next' for new file, 'exit' to quit, 'view_memory' to see history, 'clear_memory' to reset): what is the context of this image\n",
            "Answer: Based on the provided text data, it appears that the context is related to astrophysics or cosmology, specifically discussing black holes.\n",
            "\n",
            "Here's a breakdown of the insights gathered from the data:\n",
            "\n",
            "1. **Content Analysis**: The text mentions \"gravity results from a massive amount of matter packed into a very small space,\" which is a characteristic of black holes. It further elaborates on the formation of black holes, mentioning the collapse of massive stars and supernovae.\n",
            "\n",
            "2. **Relevant Entities**: Key entities mentioned include \"black holes,\" \"massive stars,\" \"supernova,\" and \"galaxies.\" These are all relevant to astrophysical or cosmological discussions.\n",
            "\n",
            "3. **Source Credibility**: The text references NASA (.gov), a credible and authoritative source in the field of space and astrophysics research. This suggests that the information is based on scientific research or findings.\n",
            "\n",
            "4. **Memory of Past Interactions**: While there's no direct past interaction related to this specific text, the format and content suggest a educational or informative context, possibly from a webpage, document, or presentation discussing astrophysical phenomena.\n",
            "\n",
            "**Insight**: The context of the image or the associated content is likely related to an educational or informative resource about black holes, their formation, and their relation to galaxies. The image might be an illustration or a representation related to black holes or astrophysics.\n",
            "\n",
            "**Probable Image Context**: Given the text, the image could be a visual representation of a black hole, its effects on space-time, or an illustration of a supernova. It might also be a graphical representation of a galaxy with a supermassive black hole at its center.\n",
            "Ask a question about the data (or 'next' for new file, 'exit' to quit, 'view_memory' to see history, 'clear_memory' to reset): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualizations such as histograms and bar graphs are saved in the local storage of Google Colab.**"
      ],
      "metadata": {
        "id": "xES3pwc2PLND"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ph10cYTXODlc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}